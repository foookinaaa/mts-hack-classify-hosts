{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d21f4c73",
   "metadata": {},
   "source": [
    "# Classification hosts on users and tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d1c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import validators\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be31e8b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5029697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_v3.csv')  # выборка после паука: парсинг сайтов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715c2c9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>is_tech_v3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>api.youla.io</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>favicon.yandex.net</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w-74721.fp.kaspersky-labs.com</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>questtime.net</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passport-authproxy.taxi.yandex.net</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 host  is_tech_v3\n",
       "0                        api.youla.io        True\n",
       "1                  favicon.yandex.net        True\n",
       "2       w-74721.fp.kaspersky-labs.com        True\n",
       "3                       questtime.net       False\n",
       "4  passport-authproxy.taxi.yandex.net        True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['host', 'is_tech_v3']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f995d",
   "metadata": {},
   "source": [
    "host: имя хоста  \n",
    "is_tech (target): 1(True) - если хост технический, 0(False) - пользовательский"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8494d0",
   "metadata": {},
   "source": [
    "### Набор правил для разметки технических и пользовательских хостов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad3dc4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('data/good_hosts.txt') as f:  # kaggle dataset\n",
    "    good_hosts = set(json.load(f))\n",
    "\n",
    "good_hosts_v2 = {\n",
    "    h.replace('www.', '')\n",
    "    for h in good_hosts\n",
    "}\n",
    "\n",
    "with open('data/rambler.json') as f:  # nice host list\n",
    "    rambler = json.load(f)\n",
    "\n",
    "rambler_wo_www = {\n",
    "    h.replace('www.', '')\n",
    "    for h in rambler\n",
    "}\n",
    "rambler.extend(rambler_wo_www)\n",
    "\n",
    "with open('data/tlds-alpha-by-domain.txt') as f:  # domain endings\n",
    "    domain_root_zones = f.readlines()\n",
    "    domain_root_zones = [\n",
    "        d[:-1].lower()\n",
    "        for d in domain_root_zones\n",
    "    ]\n",
    "\n",
    "with open('data/all_english_words.json') as f:  # english words\n",
    "    english_words = json.load(f)\n",
    "\n",
    "sites = pd.read_csv('data/sites.csv', names=['URL'])  # # nice host list\n",
    "good_hosts_v3_sites_wo_www = {\n",
    "    h.replace('www.', '')\n",
    "    for h in sites['URL'].values\n",
    "}\n",
    "good_hosts_v3 = list(sites['URL'].values)\n",
    "good_hosts_v3.extend(good_hosts_v3_sites_wo_www)\n",
    "\n",
    "\n",
    "def is_contains_english_words(s):\n",
    "    s = s.lower()\n",
    "    return any(\n",
    "        w in s\n",
    "        for w in english_words\n",
    "    )\n",
    "\n",
    "\n",
    "re_is_ip = re.compile('^((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)$') # ip adress\n",
    "re_m = re.compile('^m[0-9]+') # m + number\n",
    "re_2numbers = re.compile('\\d{3}')\n",
    "re_dynamic_prefix = re.compile('^[a-z]{1,2}[0-9]{1,}[\\-\\._]')\n",
    "re_cache_prefix = re.compile('cache-?[0-9]{1,2}')\n",
    "re_digits_only = re.compile('^[0-9]+$')\n",
    "re_infra_prefix = re.compile('^infra-[0-9]+')\n",
    "\n",
    "www_ignore_pattern = [\n",
    "    'www.gstatic.com',\n",
    "    'www.googleadservices.com',\n",
    "    'www.googleapis.com',\n",
    "    'www.google-analytics.com',\n",
    "    'www.googletagmanager.com',\n",
    "    'www.tns-counter.ru',\n",
    "    'www.googletagservices.com',\n",
    "    'cdn'\n",
    "]\n",
    "\n",
    "tech_patterns_contains = [\n",
    "    'api.',\n",
    "    '.api',\n",
    "    'cdn',\n",
    "    'ad.',\n",
    "    'ads.',\n",
    "    'static.',\n",
    "    's3.',\n",
    "    'cache.',\n",
    "    'stat.',\n",
    "    'logs.',\n",
    "    'log.',\n",
    "    'stats.',\n",
    "    'auth.',\n",
    "    'sentry.',\n",
    "    'script.',\n",
    "    'storage.',\n",
    "    '--',\n",
    "    'an.yandex.ru',\n",
    "    'app-measurement.com',\n",
    "    'tpc.googlesyndication.com',\n",
    "    'tpc.googlesyndication.com',\n",
    "    'favicon.yandex.net',\n",
    "    'googlesyndication.com',\n",
    "]\n",
    "tech_pattern_starts = [\n",
    "    'api',\n",
    "    'proxy',\n",
    "    'log',\n",
    "    'static',\n",
    "    'counter',\n",
    "    'sync.',\n",
    "    's.',\n",
    "    'a.',\n",
    "    'c.',\n",
    "    'pixel.',\n",
    "    'v1.',\n",
    "    'ssp.',\n",
    "    'img.',\n",
    "    'rtb.',\n",
    "    'code.',\n",
    "    'cm.',\n",
    "    't.',\n",
    "    'app.',\n",
    "    'grs.',\n",
    "    'analytics.',\n",
    "    'match.',\n",
    "    'adservice.',\n",
    "    'data.',\n",
    "    'd.',\n",
    "    'mc.',\n",
    "    'track.',\n",
    "    'assets',\n",
    "    'st.',\n",
    "    'js',\n",
    "    'connect.',\n",
    "    'media.',\n",
    "    'pagead2.',\n",
    "    'dl.',\n",
    "    'ajax.',\n",
    "    'content.',\n",
    "    'i.',\n",
    "    'tracking.',\n",
    "    'graph.',\n",
    "    'banners.',\n",
    "    'widget.',\n",
    "    'abtest.',\n",
    "    'strm.yandex.ru',\n",
    "    'yabs.yandex.ru',\n",
    "    'push.yandex.ru',\n",
    "    'bs.yandex.ru',\n",
    "    'statistics.',\n",
    "    'tags.',\n",
    "    'cs',\n",
    "    'adx',\n",
    "    'img',\n",
    "    'image',\n",
    "    'ads',\n",
    "    'ct.',\n",
    "    'pics.',\n",
    "    'clk.',\n",
    "    'notify.',\n",
    "    'data',\n",
    "    'ocsp.',\n",
    "    'files.',\n",
    "    'dl-',\n",
    "    'token.',\n",
    "    'graphql.',\n",
    "    'pushserver',\n",
    "    'balancer.',\n",
    "    'go.',\n",
    "    'informer.',\n",
    "    'clck.',\n",
    "    'clicks.',\n",
    "    'click.',\n",
    "    'target.',\n",
    "    'xray.',\n",
    "    'tiles.',\n",
    "    'gridserver.',\n",
    "    'metrika.',\n",
    "    'ntp.',\n",
    "    'fronterr.',\n",
    "    'lib.',\n",
    "    'tracker',\n",
    "    'appgateway',\n",
    "    'frontend.',\n",
    "    'mfa.',\n",
    "    'gate.',\n",
    "    'edge.',\n",
    "    'chat.',\n",
    "    'config.',\n",
    "    'amp.',\n",
    "    'widgets.',\n",
    "    'dev.',\n",
    "    'admin.',\n",
    "    'health.',\n",
    "    'callback.',\n",
    "    'post.',\n",
    "    'xxx-files',\n",
    "    'cluster.',\n",
    "    'ext.',\n",
    "    'file.',\n",
    "    'links.',\n",
    "    'metrics',\n",
    "]\n",
    "\n",
    "tech_patterns_ends = [\n",
    "    '.local',\n",
    "    'googleapis.com',\n",
    "    'googleusercontent.com',\n",
    "    'vkuser.net',\n",
    "    '.akamai',\n",
    "    '.link',\n",
    "    '.googleadservices',\n",
    "    '.googleadserv',\n",
    "]\n",
    "\n",
    "non_tech_pattern_starts = set([\n",
    "    'www.',\n",
    "    'm.',\n",
    "    \"maps\",\n",
    "    \"video\",\n",
    "    \"online\",\n",
    "    \"news\",\n",
    "    \"forum\",\n",
    "    \"berezniki\",\n",
    "    \"mobile\",\n",
    "    \"mail\",\n",
    "    'web.',\n",
    "    'pda.',\n",
    "    'wap.',\n",
    "])\n",
    "\n",
    "\n",
    "def predict_baseline(s):\n",
    "    # non tech start patterns\n",
    "    if any(s.startswith(p) for p in non_tech_pattern_starts):\n",
    "        return False\n",
    "    \n",
    "    # ip adress = tech\n",
    "    if re_is_ip.search(s) is not None:\n",
    "        return True\n",
    "\n",
    "    # if host is not exist = tech\n",
    "    if not (validators.domain(s) is True):\n",
    "        return True\n",
    "    \n",
    "\n",
    "    # if is not usual domain ending = tech\n",
    "    if not any(s.endswith(p) for p in domain_root_zones):\n",
    "        return True\n",
    "\n",
    "    # tech hosts\n",
    "    if any(p in s for p in www_ignore_pattern):\n",
    "        return True\n",
    "\n",
    "    # tech endings\n",
    "    if any(s.endswith(p) for p in tech_patterns_ends):\n",
    "        return True\n",
    "\n",
    "    # non tech hosts \n",
    "    if s in good_hosts:\n",
    "        return False\n",
    "    if s in good_hosts_v2:\n",
    "        return False\n",
    "    if s in good_hosts_v3:\n",
    "        return False\n",
    "    if s in rambler:\n",
    "        return False\n",
    "\n",
    "    # TECH:\n",
    "    # tech contains patterns\n",
    "    return any(p in s for p in tech_patterns_contains) or (\n",
    "            # len parts of host > 3 and wo 'www', 'm.'\n",
    "            len(s.split('.')) > 3 and not s.startswith('www.') and not s.startswith('m.')\n",
    "    # tech starts\n",
    "    ) or any(s.startswith(p) for p in tech_pattern_starts) or (\n",
    "                    # len first part > 10 and len all parts >= 3\n",
    "                   len(s.split('.')[0]) > 10 and len(s.split('.')) >= 3\n",
    "            # has m + number\n",
    "           ) or re_m.search(s) is not None or (\n",
    "                    # has 'google.com' but not for user\n",
    "                   s.endswith('google.com') and s != 'www.google.com'\n",
    "           ) or ( # 2 parts, len >25, 2 numbers together, has '-'\n",
    "                   len(s.split('.')) == 2 and len(s) > 25 and re_2numbers.search(s) is not None and '-' in s\n",
    "           ) or ( # >2 parts, has 'api'\n",
    "                   len(s.split('.')) > 2 and 'api' in s.split('.')[0]\n",
    "           ) or ( # >2 parts, has 'node'\n",
    "                   len(s.split('.')) > 2 and 'node' in s.split('.')[0]\n",
    "           ) or ( # >2 parts, start with 's'\n",
    "                   len(s.split('.')) > 2 and s.split('.')[0].startswith('s')\n",
    "           ) or ( # >2 parts, has letter + number\n",
    "                   len(s.split('.')) > 2 and re_dynamic_prefix.search(s) is not None\n",
    "           ) or ( # >2 parts, has 'cache'\n",
    "                   len(s.split('.')) > 2 and re_cache_prefix.search(s) is not None\n",
    "           ) or ( # >2 parts, has numbers in first part\n",
    "                   len(s.split('.')) > 2 and re_digits_only.search(s.split('.')[0]) is not None\n",
    "           ) or ( # >2 parts, len first part = 1, and it's not 'm' (like mobile)\n",
    "                   len(s.split('.')) > 2 and len(s.split('.')[0]) == 1 and s.split('.')[0] != 'm'\n",
    "           ) or ( # >2 parts, len first part = 2, and it's not lang abb\n",
    "                   len(s.split('.')) > 2 and len(s.split('.')[0]) == 2 and s.split('.')[0] not in {\n",
    "               'ru', 'en', 'de', 'us'\n",
    "           } \n",
    "           ) or ( # >2 parts, has 'infra' + number in first part\n",
    "                   len(s.split('.')) > 2 and re_infra_prefix.search(s.split('.')[0]) is not None\n",
    "           ) or ( # >2 parts, has 'auth' + number in first part\n",
    "                   len(s.split('.')) > 2 and 'auth' in s.split('.')[0]\n",
    "           ) or ( # >2 parts, has ... in first part\n",
    "                   len(s.split('.')) > 2 and s.split('.')[0] in {\n",
    "               'us-east-2',\n",
    "               'us-east-1',\n",
    "               'us-west-1',\n",
    "               'us-west-2',\n",
    "               'af-south-1',\n",
    "               'ap-east-1',\n",
    "               'ap-south-1',\n",
    "               'ap-northeast-3',\n",
    "               'ap-northeast-2',\n",
    "               'ap-southeast-1',\n",
    "               'ap-southeast-2',\n",
    "               'ap-northeast-1',\n",
    "               'ca-central-1',\n",
    "               'eu-central-1',\n",
    "               'eu-west-1',\n",
    "               'eu-west-2',\n",
    "               'eu-south-1',\n",
    "               'eu-west-3',\n",
    "               'eu-north-1',\n",
    "               'me-south-1',\n",
    "               'sa-east-1',\n",
    "               'us-gov-east-1',\n",
    "               'us-gov-west-1'\n",
    "           }\n",
    "           ) or ( # >2 parts, has 'counter' in first part\n",
    "                   len(s.split('.')) > 2 and 'counter' in s.split('.')[0]\n",
    "           ) or ( # >2 parts, has not eng words in first part\n",
    "                   len(s.split('.')) > 2 and not is_contains_english_words(s.split('.')[0])\n",
    "           ) or ( # has not eng words in all not ending parts\n",
    "               not is_contains_english_words(\n",
    "                   ''.join(s.split('.')[:-1])\n",
    "               )\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d01cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8642ef9bc44126bbf0d2142879d29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hosts = df['host'].values.tolist()\n",
    "is_tech = [\n",
    "    predict_baseline(hosts[host])\n",
    "    for host in trange(len(hosts))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c6f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_tech'] = is_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec53440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8405403512983636"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_tech'].sum() / len(df['is_tech'])  # 84% hosts is tech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448556c",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755e6ba",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efaefc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import eli5\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687fce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[['host']], df['is_tech'].values.astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43c8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change because of metrics (users hosts more important)\n",
    "y = pd.Series(y).map({\n",
    "                         1: 0,\n",
    "                         0: 1\n",
    "                     })  # 1 - users, 0 - tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6860e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X[['host']], y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee0e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 ngrams\n",
    "def create_ngrams():\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train['host'].str.replace('.', ''))\n",
    "    vectorizer_model = LogisticRegression(C=5e1, solver='liblinear', random_state=17, n_jobs=1)\n",
    "    vectorizer_model.fit(X_train_tfidf, [int(y_i) for y_i in y_train])\n",
    "\n",
    "    vectorizer_model_weights = eli5.formatters.as_dataframe.explain_weights_df(\n",
    "        estimator=vectorizer_model,\n",
    "        feature_names=list(vectorizer.get_feature_names()),\n",
    "        top=(100, 10)\n",
    "    )\n",
    "    return vectorizer_model_weights.set_index('feature')['weight'].to_dict()\n",
    "\n",
    "ngrams = create_ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "944ad40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(hosts, ngram):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "\n",
    "    df_features = pd.DataFrame()\n",
    "    df_features['host'] = hosts\n",
    "    df_features['url_len'] = df_features['host'].apply(lambda s: len(s))\n",
    "    df_features['max_domain_level'] = df_features['host'].apply(lambda s: len(s.split('.')))\n",
    "    df_features['max_domain_part_len'] = df_features['host'].apply(\n",
    "        lambda s: max((len(s_i) for s_i in s.split('.'))))\n",
    "\n",
    "    df_features['ngram_max'] = df_features['host'].apply(lambda s: max([\n",
    "                                                                           ngrams[ngram]\n",
    "                                                                           for ngram in ngrams.keys()\n",
    "                                                                           if ngram in s\n",
    "                                                                       ] + [0]))\n",
    "\n",
    "    df_features['ngram_min'] = df_features['host'].apply(lambda s: min([\n",
    "                                                                           ngrams[ngram]\n",
    "                                                                           for ngram in ngrams.keys()\n",
    "                                                                           if ngram in s\n",
    "                                                                       ] + [0]))\n",
    "    df_features['users_start'] = df_features['host'].apply(lambda s: (s.startswith('www.')) or \n",
    "                                                           (s.startswith('m.')))\n",
    "\n",
    "    re_digit = re.compile('\\D')\n",
    "    df_features['digits_count'] = df_features['host'].apply(lambda s: len(re_digit.sub('', s)))\n",
    "\n",
    "    del df_features['host']\n",
    "\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cfc3d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_features(X_train['host'].tolist(), ngrams)\n",
    "X_test = create_features(X_test['host'].tolist(), ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b62e5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits_count           32.667387\n",
      "max_domain_level       31.093086\n",
      "url_len                11.334012\n",
      "users_start            10.233795\n",
      "ngram_min               5.532076\n",
      "max_domain_part_len     4.684761\n",
      "ngram_max               4.454882\n",
      "dtype: float64\n",
      "precision=0.93\n",
      "recall=0.61\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(random_state=0, verbose=0, max_depth=3, n_estimators=5)\n",
    "booster = model.fit(X_train, y_train)\n",
    "print(pd.Series(dict(zip(booster.feature_names_, booster.feature_importances_))).sort_values(ascending=False))\n",
    "predicts = booster.predict(X_test)\n",
    "print(f'precision={round(precision_score(y_test, predicts), 2)}')\n",
    "print(f'recall={round(recall_score(y_test, predicts), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284c0f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92134499, 0.0854344 , 0.0854344 , 0.0854344 , 0.92134499,\n",
       "       0.92134499])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_url = ['yandex.ru', 'api.yandex.ru', 'cdn.vtb.ru', 'no-cdn.vtb.ru', 'rbc.ru', 'ya.ru']\n",
    "\n",
    "booster.predict_proba(create_features(golden_url, ngrams))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847974d7",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "863cbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hosts by hands\n",
    "df_val_1 = pd.read_csv('validation_manual/df_non_tech_manual.csv')\n",
    "df_val_1 = df_val_1[['host', 'is_tech_manual']]\n",
    "df_val_1.loc[df_val_1['is_tech_manual'] == ' ', 'is_tech_manual'] = 1\n",
    "df_val_1.dropna(inplace=True)\n",
    "df_val_1['is_tech_manual'] = df_val_1['is_tech_manual'].astype('int')\n",
    "\n",
    "df_val_2 = pd.read_csv('validation_manual/output_AM.csv')\n",
    "df_val_2 = df_val_2[['host', 'is_tech_manual']]\n",
    "df_val_2['is_tech_manual'] = df_val_2['is_tech_manual'].astype('int')\n",
    "\n",
    "df_val = pd.concat([df_val_1, df_val_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5a21159",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = df_val['host']\n",
    "y_val = df_val['is_tech_manual'].map({\n",
    "                                         1: 0,\n",
    "                                         0: 1\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9cc01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = create_features(X_val.tolist(), ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f3074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.73\n",
      "recall=0.59\n"
     ]
    }
   ],
   "source": [
    "predicts = booster.predict(X_val)\n",
    "print(f'precision={round(precision_score(y_val, predicts), 2)}')\n",
    "print(f'recall={round(recall_score(y_val, predicts), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c99f7b",
   "metadata": {},
   "source": [
    "# Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c7a83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedPredictor:\n",
    "    def __init__(self, booster, ngrams):\n",
    "        self._booster = booster\n",
    "        self._ngrams = ngrams\n",
    "\n",
    "    def predict(self, hosts):\n",
    "        return self._predict(self._booster, self._create_features(hosts, self._ngrams))\n",
    "\n",
    "    @classmethod\n",
    "    def _create_features(cls, hosts, ngrams):\n",
    "        # copy features extract pipeline\n",
    "        import pandas as pd\n",
    "        import re\n",
    "\n",
    "        df_features = pd.DataFrame()\n",
    "        df_features['host'] = hosts\n",
    "        df_features['url_len'] = df_features['host'].apply(lambda s: len(s))\n",
    "        df_features['max_domain_level'] = df_features['host'].apply(lambda s: len(s.split('.')))\n",
    "        df_features['max_domain_part_len'] = df_features['host'].apply(\n",
    "            lambda s: max((len(s_i) for s_i in s.split('.'))))\n",
    "\n",
    "        df_features['ngram_max'] = df_features['host'].apply(lambda s: max([\n",
    "                                                                               ngrams[ngram]\n",
    "                                                                               for ngram in ngrams.keys()\n",
    "                                                                               if ngram in s\n",
    "                                                                           ] + [0]))\n",
    "\n",
    "        df_features['ngram_min'] = df_features['host'].apply(lambda s: min([\n",
    "                                                                               ngrams[ngram]\n",
    "                                                                               for ngram in ngrams.keys()\n",
    "                                                                               if ngram in s\n",
    "                                                                           ] + [0]))\n",
    "        df_features['users_start'] = df_features['host'].apply(lambda s: (s.startswith('www.')) or \n",
    "                                                           (s.startswith('m.')))\n",
    "\n",
    "        re_digit = re.compile('\\D')\n",
    "        df_features['digits_count'] = df_features['host'].apply(lambda s: len(re_digit.sub('', s)))\n",
    "\n",
    "        del df_features['host']\n",
    "\n",
    "        return df_features\n",
    "\n",
    "    @classmethod\n",
    "    def _predict(cls, booster, df_features):\n",
    "        import shap\n",
    "\n",
    "        russian_names = {\n",
    "            'url_len': 'Длина хоста',\n",
    "            'max_domain_level': 'Количество поддоменов',\n",
    "            'max_domain_part_len': 'Максимальная длина поддомена',\n",
    "            'ngram_max': 'Максимальный вес n-граммы',\n",
    "            'ngram_min': 'Минимальный вес n-граммы',\n",
    "            'digits_count': 'Число цифр в хосте',\n",
    "            'users_start' : 'Начало с www. или с m.'\n",
    "        }\n",
    "\n",
    "        explainer = shap.Explainer(booster)\n",
    "        predicted_proba = round(booster.predict_proba(df_features)[0][1], 2)\n",
    "        shap_values = explainer(df_features)\n",
    "        shap_feature_importance = dict(zip(\n",
    "            [russian_names.get(n, n) for n in shap_values.feature_names],\n",
    "            [\n",
    "                round(x, 2)\n",
    "                for x in shap_values.values[0].tolist()\n",
    "            ]\n",
    "        ))\n",
    "        predicted_proba = float(predicted_proba)\n",
    "\n",
    "        return {\n",
    "            'predict': predicted_proba > 0.5,\n",
    "            'predicted_proba': predicted_proba,\n",
    "            'shap_feature_importance': shap_feature_importance\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c27b728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "booster_export = model.fit(create_features(X['host'].tolist(), ngrams), y)\n",
    "predictor = SharedPredictor(booster_export, ngrams)\n",
    "with open('data/model.bin', 'wb') as f:\n",
    "    dill.dump(predictor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abadab8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predict': False,\n",
       " 'predicted_proba': 0.09,\n",
       " 'shap_feature_importance': {'Длина хоста': 0.37,\n",
       "  'Количество поддоменов': -0.23,\n",
       "  'Максимальная длина поддомена': 0.0,\n",
       "  'Максимальный вес n-граммы': -0.07,\n",
       "  'Минимальный вес n-граммы': -0.94,\n",
       "  'Начало с www. или с m.': -0.07,\n",
       "  'Число цифр в хосте': 0.66}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "predictor.predict(['api.yandex.ru']) # False = tech host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7824d683",
   "metadata": {},
   "source": [
    "# check errors\n",
    "Анализ ошибок модели, на основе которого можно далее создавать новые фичи для улучшения качества предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bc4a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7863f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(np.vstack([y_val, pd.Series(predicts)])).T\n",
    "check.columns = ['true', 'pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d6b15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = df_val.join(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7be6203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host</th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitdmp.whiteboxdigital.ru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mitdmp.whiteboxdigital.ru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsp.e-contenta.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dsp.e-contenta.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobile.yandexadexchange.net</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>m.vk.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>v-fall.net</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>lookaside.facebook.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ice.360yield.com</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>leafletjs.com</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            host  true  pred\n",
       "4      mitdmp.whiteboxdigital.ru     1     0\n",
       "4      mitdmp.whiteboxdigital.ru     1     0\n",
       "7             dsp.e-contenta.com     1     0\n",
       "7             dsp.e-contenta.com     1     0\n",
       "8    mobile.yandexadexchange.net     1     0\n",
       "..                           ...   ...   ...\n",
       "183                     m.vk.com     1     0\n",
       "184                   v-fall.net     1     0\n",
       "190       lookaside.facebook.com     0     1\n",
       "195             ice.360yield.com     0     1\n",
       "198                leafletjs.com     1     0\n",
       "\n",
       "[78 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[check['true'] != check['pred']][['host', 'true', 'pred']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
